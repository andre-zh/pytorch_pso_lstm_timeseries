{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.导入包以及设置随机种子\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.以类的方式定义超参数\n",
    "class argparse():\n",
    "    pass\n",
    "\n",
    "args = argparse()\n",
    "args.epochs, args.learning_rate, args.patience = [30, 0.001, 4]\n",
    "args.hidden_size, args.input_size= [40, 30]\n",
    "args.device, = [torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.定义模型\n",
    "class Your_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Your_model, self).__init__()\n",
    "        pass\n",
    "        \n",
    "    def forward(self,x):\n",
    "        pass\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.定义early stopping\n",
    "class EarlyStopping():\n",
    "    def __init__(self,patience=7,verbose=False,delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "    def __call__(self,val_loss,model,path):\n",
    "        print(\"val_loss={}\".format(val_loss))\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss,model,path)\n",
    "        elif score < self.best_score+self.delta:\n",
    "            self.counter+=1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter>=self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss,model,path)\n",
    "            self.counter = 0\n",
    "    def save_checkpoint(self,val_loss,model,path):\n",
    "        if self.verbose:\n",
    "            print(\n",
    "                f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), path+'/'+'model_checkpoint.pth')\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.定义自己的数据集Dataset,DataLoader\n",
    "class Dataset_name(Dataset):\n",
    "    def __init__(self, flag='train'):\n",
    "        assert flag in ['train', 'test', 'valid']\n",
    "        self.flag = flag\n",
    "        self.__load_data__()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        pass\n",
    "    def __len__(self):\n",
    "        pass\n",
    "\n",
    "    def __load_data__(self, csv_paths: list):\n",
    "        pass\n",
    "        print(\n",
    "            \"train_X.shape:{}\\ntrain_Y.shape:{}\\nvalid_X.shape:{}\\nvalid_Y.shape:{}\\n\"\n",
    "            .format(self.train_X.shape, self.train_Y.shape, self.valid_X.shape, self.valid_Y.shape))\n",
    "\n",
    "train_dataset = Dataset_name(flag='train')\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "valid_dataset = Dataset_name(flag='valid')\n",
    "valid_dataloader = DataLoader(dataset=valid_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.实例化模型，设置loss，优化器等\n",
    "model = Your_model().to(args.device)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(Your_model.parameters(),lr=args.learning_rate)\n",
    "\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "train_epochs_loss = []\n",
    "valid_epochs_loss = []\n",
    "\n",
    "early_stopping = EarlyStopping(patience=args.patience,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.开始训练以及调整lr\n",
    "for epoch in range(args.epochs):\n",
    "    Your_model.train()\n",
    "    train_epoch_loss = []\n",
    "    for idx,(data_x,data_y) in enumerate(train_dataloader,0):\n",
    "        data_x = data_x.to(torch.float32).to(args.device)\n",
    "        data_y = data_y.to(torch.float32).to(args.device)\n",
    "        outputs = Your_model(data_x)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(data_y,outputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_epoch_loss.append(loss.item())\n",
    "        train_loss.append(loss.item())\n",
    "        if idx%(len(train_dataloader)//2)==0:\n",
    "            print(\"epoch={}/{},{}/{}of train, loss={}\".format(\n",
    "                epoch, args.epochs, idx, len(train_dataloader),loss.item()))\n",
    "    train_epochs_loss.append(np.average(train_epoch_loss))\n",
    "    \n",
    "    #=====================valid============================\n",
    "    Your_model.eval()\n",
    "    valid_epoch_loss = []\n",
    "    for idx,(data_x,data_y) in enumerate(valid_dataloader,0):\n",
    "        data_x = data_x.to(torch.float32).to(args.device)\n",
    "        data_y = data_y.to(torch.float32).to(args.device)\n",
    "        outputs = Your_model(data_x)\n",
    "        loss = criterion(outputs,data_y)\n",
    "        valid_epoch_loss.append(loss.item())\n",
    "        valid_loss.append(loss.item())\n",
    "    valid_epochs_loss.append(np.average(valid_epoch_loss))\n",
    "    #==================early stopping======================\n",
    "    early_stopping(valid_epochs_loss[-1],model=Your_model,path=r'c:\\\\your_model_to_save')\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "    #====================adjust lr========================\n",
    "    lr_adjust = {\n",
    "            2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "            10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "        }\n",
    "    if epoch in lr_adjust.keys():\n",
    "        lr = lr_adjust[epoch]\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        print('Updating learning rate to {}'.format(lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.绘图\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(121)\n",
    "plt.plot(train_loss[:])\n",
    "plt.title(\"train_loss\")\n",
    "plt.subplot(122)\n",
    "plt.plot(train_epochs_loss[1:],'-o',label=\"train_loss\")\n",
    "plt.plot(valid_epochs_loss[1:],'-o',label=\"valid_loss\")\n",
    "plt.title(\"epochs_loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.预测\n",
    "# 此处可定义一个预测集的Dataloader。也可以直接将你的预测数据reshape,添加batch_size=1\n",
    "Your_model.eval()\n",
    "predict = Your_model(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('p310-z': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4fe1639d8527fead20cc4ef0bb6e35c875be340e7203d300b81ef3878c6c1f21"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
